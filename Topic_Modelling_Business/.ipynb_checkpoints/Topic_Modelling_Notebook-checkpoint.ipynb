{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2Ej2XMTES30"
   },
   "source": [
    "## Topic Modelling For Business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSx6eUQEES33"
   },
   "source": [
    "For this project we will use the articles on the emerging trend of:\n",
    "\n",
    "### Digital Economy\n",
    "\n",
    "The dataset hosts 2488 articles in this topic. The summary of each topic will be used as the base for the topic models.\n",
    " \n",
    " \n",
    "  \n",
    "   \n",
    "This project is divided in 6 tasks:\n",
    "\n",
    "####Task 1: Introduction to the dataset\n",
    "####Task 2: Data cleaning and preparation\n",
    "####Task 3: Exploratory analysis with WordCloud\n",
    "####Task 4: Prepare data for Topic Modelling\n",
    "####Task 5: Build Topic Model\n",
    "####Task 6: Visualize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTZfCBCgadIm"
   },
   "source": [
    "###Task 1: Introduction to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsHpRpcRES33"
   },
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZ2cYbYzES34"
   },
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import numpy as np\n",
    "import re, nltk, spacy, gensim\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDFS1eflGrdU"
   },
   "outputs": [],
   "source": [
    "# Upload .csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndRXgIMPGvH4"
   },
   "outputs": [],
   "source": [
    "# Store dataset in a Pandas Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JlCav8pnES37"
   },
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1lrsg74ES38"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqBQF3mzES3_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UtK3F1qVES4D"
   },
   "source": [
    "### Task 2: Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CmCvN-fdWfOa"
   },
   "source": [
    "Models will be built on the column 'Abstract'.\n",
    "Other columns could be used for exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VqwFL9pW21V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc3AQj_PES4D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8Ob_edXES4G"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Note the drop in number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZaULBVYES4M"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "df['p_abstract'] = \n",
    "\n",
    "# Convert the titles to lowercase\n",
    "df['p_abstract'] = \n",
    "\n",
    "# Print out the first rows of papers\n",
    "df['p_abstract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktvV2c9zES4Q"
   },
   "source": [
    "### Task 3: Exploratory Analysis with WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZsZaY_hW7B2"
   },
   "source": [
    "Build wordclouds for Title and Abstract fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYk8fOD9ES4Q"
   },
   "outputs": [],
   "source": [
    "#For Title\n",
    "\n",
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Join the different titles together.\n",
    "long_string = ','.join(list(df['Title'].values))\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = \n",
    "\n",
    "# Visualize the word cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJQ_hqd3XDRr"
   },
   "source": [
    "Exercise: Build a wordcloud with top 200 words using Abstract field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mr8Ydj30ES4T"
   },
   "outputs": [],
   "source": [
    "#For Abstract\n",
    "#Print only top 200 words\n",
    "\n",
    "# Join the different processed abstracts together.\n",
    "\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud2 = \n",
    "\n",
    "# Visualize the word cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SjEW-dVXQGc"
   },
   "source": [
    "Remove the commonly used words (or irrelevant according to the context) from the wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HyZBltXAES4Z"
   },
   "outputs": [],
   "source": [
    "## Remove STOPWORDS taking reference from previous wordcloud\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "## Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"research\", \"economic\", \"study\", \"data\", \"development\", \"result\", \"analysis\", \"model\", \n",
    "                 \"based\", \"using\", \"new\", \"market\", \"business\", \"system\", \"use\"])\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud3 = WordCloud\n",
    "\n",
    "# Visualize the word cloud\n",
    "wordcloud3.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TKDQA1yU8MS"
   },
   "source": [
    "###Task 4: Prepare data for Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqChF_awXdWP"
   },
   "source": [
    "Step 1: Split sentences to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvpnT50oES4c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEN1voUlXhoF"
   },
   "source": [
    "Step 2: Build N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2YNi_hHES4f"
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram =                                                  # higher threshold fewer phrases.\n",
    "trigram = \n",
    "# Faster way to get a sentence formatted as a bigram or trigram\n",
    "bigram_mod = \n",
    "trigram_mod = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOPsgKZVXmSu"
   },
   "source": [
    "Step 3: Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCUe4k7rES4i"
   },
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['research', 'study', 'data', 'development', 'result', 'analysis', 'model', \n",
    "                 'based', 'using', 'new', 'market', 'business', 'system', 'use'])\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return \n",
    "def make_bigrams(texts):\n",
    "    return \n",
    "def make_trigrams(texts):\n",
    "    return \n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8VPRHd8X8SB"
   },
   "source": [
    "Step 4: Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkQbLNuXES4k"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Remove Stop Words\n",
    "data_words_nostops = \n",
    "# Form Bigrams\n",
    "data_words_bigrams = \n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = \n",
    "# Lemmatize keeping only noun, adj, vb, adv\n",
    "data_lemmatized = \n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNkpqIB3X_02"
   },
   "source": [
    "Step 5: Build Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "280bhxOfES4m"
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = \n",
    "# Create Corpus\n",
    "texts = \n",
    "# Term Document Frequency\n",
    "corpus = \n",
    "# View\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRZ7LK5pVLlv"
   },
   "source": [
    "###Task 5: Build topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKlbZDMlES4r"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YafZ1ZOnES4t"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3sPZwLuES4v"
   },
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', )  # a measure of how good the model is. Lower value is preferred.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = \n",
    "coherence_lda = \n",
    "print('\\nCoherence Score: ', )\n",
    "\n",
    "# Compute Coherence Score using UMass\n",
    "coherence_model_lda = \n",
    "coherence_lda = \n",
    "print('\\nCoherence Score u_mass: ', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bW73MgdeVltj"
   },
   "source": [
    "###Task 6: Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5XzNXSYVqfk"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "!pip install -U pyLDAvis\n",
    "import pyLDAvis.gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgSofMHoYzY8"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = \n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z67ko8fcES5C"
   },
   "source": [
    "References\n",
    "\n",
    "Liu, L., Tang, L., Dong, W., Yao, S., & Zhou, W. (2016). An overview of topic modeling and its current applications in bioinformatics. SpringerPlus, 5(1), 1608. https://doi.org/10.1186/s40064-016-3252-8)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Topic Modelling Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
